{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names=[f's_{i}' for i in range(1,22)]\n",
    "settings=['set_1','set_2','set_3']\n",
    "cols=['unit_nr','time_cycles']+settings+sensor_names\n",
    "train=pd.read_csv(('CMAPSSData/train_FD001.txt'),sep='\\s+',header=None,names=cols) # change it here\n",
    "test=pd.read_csv(('CMAPSSData/test_FD001.txt'),sep='\\s+',header=None,names=cols)#change it here\n",
    "actual=pd.read_csv(('CMAPSSData/RUL_FD001.txt'),sep='\\s+',header=None,names=['RUL'])#change it here\n",
    "actual=actual.to_numpy().flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>set_1</th>\n",
       "      <th>set_2</th>\n",
       "      <th>set_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.75</td>\n",
       "      <td>1602.38</td>\n",
       "      <td>1422.78</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.79</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8117.69</td>\n",
       "      <td>8.5207</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>22.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>644.18</td>\n",
       "      <td>1596.17</td>\n",
       "      <td>1428.01</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.58</td>\n",
       "      <td>2388.33</td>\n",
       "      <td>8117.51</td>\n",
       "      <td>8.5183</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>23.1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.64</td>\n",
       "      <td>1599.22</td>\n",
       "      <td>1425.95</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.04</td>\n",
       "      <td>2388.35</td>\n",
       "      <td>8112.58</td>\n",
       "      <td>8.5223</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>23.0675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.34</td>\n",
       "      <td>1602.36</td>\n",
       "      <td>1425.77</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.57</td>\n",
       "      <td>2388.30</td>\n",
       "      <td>8114.61</td>\n",
       "      <td>8.5174</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.45</td>\n",
       "      <td>23.1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1601.41</td>\n",
       "      <td>1427.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.08</td>\n",
       "      <td>2388.32</td>\n",
       "      <td>8110.93</td>\n",
       "      <td>8.5113</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>22.9649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_nr  time_cycles   set_1   set_2  set_3     s_1     s_2      s_3  \\\n",
       "0          1            1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70   \n",
       "1          1            2  0.0019 -0.0003  100.0  518.67  642.15  1591.82   \n",
       "2          1            3 -0.0043  0.0003  100.0  518.67  642.35  1587.99   \n",
       "3          1            4  0.0007  0.0000  100.0  518.67  642.35  1582.79   \n",
       "4          1            5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85   \n",
       "..       ...          ...     ...     ...    ...     ...     ...      ...   \n",
       "187        1          188 -0.0067  0.0003  100.0  518.67  643.75  1602.38   \n",
       "188        1          189 -0.0006  0.0002  100.0  518.67  644.18  1596.17   \n",
       "189        1          190 -0.0027  0.0001  100.0  518.67  643.64  1599.22   \n",
       "190        1          191 -0.0000 -0.0004  100.0  518.67  643.34  1602.36   \n",
       "191        1          192  0.0009 -0.0000  100.0  518.67  643.54  1601.41   \n",
       "\n",
       "         s_4    s_5  ...    s_12     s_13     s_14    s_15  s_16  s_17  s_18  \\\n",
       "0    1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03   392  2388   \n",
       "1    1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03   392  2388   \n",
       "2    1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03   390  2388   \n",
       "3    1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03   392  2388   \n",
       "4    1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03   393  2388   \n",
       "..       ...    ...  ...     ...      ...      ...     ...   ...   ...   ...   \n",
       "187  1422.78  14.62  ...  519.79  2388.23  8117.69  8.5207  0.03   396  2388   \n",
       "188  1428.01  14.62  ...  519.58  2388.33  8117.51  8.5183  0.03   395  2388   \n",
       "189  1425.95  14.62  ...  520.04  2388.35  8112.58  8.5223  0.03   398  2388   \n",
       "190  1425.77  14.62  ...  519.57  2388.30  8114.61  8.5174  0.03   394  2388   \n",
       "191  1427.20  14.62  ...  520.08  2388.32  8110.93  8.5113  0.03   396  2388   \n",
       "\n",
       "      s_19   s_20     s_21  \n",
       "0    100.0  39.06  23.4190  \n",
       "1    100.0  39.00  23.4236  \n",
       "2    100.0  38.95  23.3442  \n",
       "3    100.0  38.88  23.3739  \n",
       "4    100.0  38.90  23.4044  \n",
       "..     ...    ...      ...  \n",
       "187  100.0  38.51  22.9588  \n",
       "188  100.0  38.48  23.1127  \n",
       "189  100.0  38.49  23.0675  \n",
       "190  100.0  38.45  23.1295  \n",
       "191  100.0  38.48  22.9649  \n",
       "\n",
       "[192 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['unit_nr']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>set_1</th>\n",
       "      <th>set_2</th>\n",
       "      <th>set_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.24</td>\n",
       "      <td>1599.45</td>\n",
       "      <td>1415.79</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.69</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8213.28</td>\n",
       "      <td>8.4715</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1595.69</td>\n",
       "      <td>1422.05</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.05</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8210.85</td>\n",
       "      <td>8.4512</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.44</td>\n",
       "      <td>1593.15</td>\n",
       "      <td>1406.82</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.18</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8217.24</td>\n",
       "      <td>8.4569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.26</td>\n",
       "      <td>1594.99</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.33</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8220.48</td>\n",
       "      <td>8.4711</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13096 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_nr  time_cycles   set_1   set_2  set_3     s_1     s_2      s_3  \\\n",
       "0            1            1  0.0023  0.0003  100.0  518.67  643.02  1585.29   \n",
       "1            1            2 -0.0027 -0.0003  100.0  518.67  641.71  1588.45   \n",
       "2            1            3  0.0003  0.0001  100.0  518.67  642.46  1586.94   \n",
       "3            1            4  0.0042  0.0000  100.0  518.67  642.44  1584.12   \n",
       "4            1            5  0.0014  0.0000  100.0  518.67  642.51  1587.19   \n",
       "...        ...          ...     ...     ...    ...     ...     ...      ...   \n",
       "13091      100          194  0.0049  0.0000  100.0  518.67  643.24  1599.45   \n",
       "13092      100          195 -0.0011 -0.0001  100.0  518.67  643.22  1595.69   \n",
       "13093      100          196 -0.0006 -0.0003  100.0  518.67  643.44  1593.15   \n",
       "13094      100          197 -0.0038  0.0001  100.0  518.67  643.26  1594.99   \n",
       "13095      100          198  0.0013  0.0003  100.0  518.67  642.95  1601.62   \n",
       "\n",
       "           s_4    s_5  ...    s_12     s_13     s_14    s_15  s_16  s_17  \\\n",
       "0      1398.21  14.62  ...  521.72  2388.03  8125.55  8.4052  0.03   392   \n",
       "1      1395.42  14.62  ...  522.16  2388.06  8139.62  8.3803  0.03   393   \n",
       "2      1401.34  14.62  ...  521.97  2388.03  8130.10  8.4441  0.03   393   \n",
       "3      1406.42  14.62  ...  521.38  2388.05  8132.90  8.3917  0.03   391   \n",
       "4      1401.92  14.62  ...  522.15  2388.03  8129.54  8.4031  0.03   390   \n",
       "...        ...    ...  ...     ...      ...      ...     ...   ...   ...   \n",
       "13091  1415.79  14.62  ...  520.69  2388.00  8213.28  8.4715  0.03   394   \n",
       "13092  1422.05  14.62  ...  521.05  2388.09  8210.85  8.4512  0.03   395   \n",
       "13093  1406.82  14.62  ...  521.18  2388.04  8217.24  8.4569  0.03   395   \n",
       "13094  1419.36  14.62  ...  521.33  2388.08  8220.48  8.4711  0.03   395   \n",
       "13095  1424.99  14.62  ...  521.07  2388.05  8214.64  8.4903  0.03   396   \n",
       "\n",
       "       s_18   s_19   s_20     s_21  \n",
       "0      2388  100.0  38.86  23.3735  \n",
       "1      2388  100.0  39.02  23.3916  \n",
       "2      2388  100.0  39.08  23.4166  \n",
       "3      2388  100.0  39.00  23.3737  \n",
       "4      2388  100.0  38.99  23.4130  \n",
       "...     ...    ...    ...      ...  \n",
       "13091  2388  100.0  38.65  23.1974  \n",
       "13092  2388  100.0  38.57  23.2771  \n",
       "13093  2388  100.0  38.62  23.2051  \n",
       "13094  2388  100.0  38.66  23.2699  \n",
       "13095  2388  100.0  38.70  23.1855  \n",
       "\n",
       "[13096 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cycle_train=[]\n",
    "for i in range(1,101):\n",
    "    row=train.loc[train['unit_nr']==i]\n",
    "    max_cycle_train.append(row['time_cycles'].max())\n",
    "\n",
    "max_cycle_test=[]\n",
    "for i in range(100):\n",
    "    row=test.loc[test['unit_nr']==i+1]['time_cycles']\n",
    "    max_cycle_test.append(len(row)+int(actual[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rul(data,max_cycle):\n",
    "    RUL=[]\n",
    "    for i,j in enumerate(max_cycle):\n",
    "        row=data.loc[data['unit_nr']==i+1]['time_cycles']\n",
    "        for k in row:\n",
    "            RUL.append(j-k)\n",
    "    return RUL\n",
    "\n",
    "train_rul=pd.DataFrame(add_rul(train,max_cycle_train))\n",
    "train['RUL']=train_rul.clip(upper=130)\n",
    "test['RUL']=(add_rul(test,max_cycle_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_sensors = ['s_1','s_5','s_6','s_10','s_16','s_18','s_19']\n",
    "index_names=['time_cycles']\n",
    "drop_labels = index_names+settings+drop_sensors\n",
    "X_train = train.drop(drop_labels, axis=1)\n",
    "X_test = test.drop(drop_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUL'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_scale=X_train.columns.to_list()\n",
    "col_to_scale.pop(0)\n",
    "col_to_scale.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s_2',\n",
       " 's_3',\n",
       " 's_4',\n",
       " 's_7',\n",
       " 's_8',\n",
       " 's_9',\n",
       " 's_11',\n",
       " 's_12',\n",
       " 's_13',\n",
       " 's_14',\n",
       " 's_15',\n",
       " 's_17',\n",
       " 's_20',\n",
       " 's_21']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(df, sensors, alpha=0.4):\n",
    "    cf=[]\n",
    "    for i in sensors:\n",
    "        C=df[i].copy()\n",
    "        X=[C[0]]\n",
    "        for i in range(1,len(C)):\n",
    "            X.append(alpha * C[i-1]+(1-alpha)*X[i-1])\n",
    "        cf.append(X)\n",
    "    return np.array(cf)\n",
    "        \n",
    "e_train=exponential_smoothing(X_train,col_to_scale,0.2)\n",
    "e_test=exponential_smoothing(X_test,col_to_scale,0.2)\n",
    "ex_train=X_train.copy()\n",
    "ex_test=X_test.copy()\n",
    "for i,j in enumerate(col_to_scale):\n",
    "    ex_train[j]=e_train[i]\n",
    "for i,j in enumerate(col_to_scale):\n",
    "    ex_test[j]=e_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "def scaling(x_scale):\n",
    "    x_scale[col_to_scale]=scaler.fit_transform(x_scale[col_to_scale])\n",
    "    return x_scale\n",
    "ex_train=scaling(ex_train)\n",
    "ex_test=scaling(ex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_train=ex_train[col_to_scale].to_numpy()\n",
    "rbm_test=ex_test[col_to_scale].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class GaussianRBM:\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.weights = np.random.randn(num_visible, num_hidden)\n",
    "        self.visible_bias = np.zeros(num_visible)\n",
    "        self.hidden_bias = np.zeros(num_hidden)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        m=[]\n",
    "        shape=x.shape\n",
    "        x=x.flatten()\n",
    "        for i in x:\n",
    "            m.append(1.0 / (1.0 + math.exp(-i)))\n",
    "        return np.array(m).reshape(shape)\n",
    "\n",
    "    def sample_hidden_given_visible(self, visible_data):\n",
    "        hidden_activations = np.dot(visible_data, self.weights) + self.hidden_bias\n",
    "        hidden_samples = np.random.normal(loc=self.sigmoid(hidden_activations), scale=1)\n",
    "        return hidden_samples\n",
    "\n",
    "    def sample_visible_given_hidden(self, hidden_data):\n",
    "        visible_activations = np.dot(hidden_data, self.weights.T) + self.visible_bias\n",
    "        visible_samples = np.random.normal(loc=self.sigmoid(visible_activations), scale=1)\n",
    "        return visible_samples\n",
    "\n",
    "    def gibbs_sampling(self, visible_data, num_steps=1):\n",
    "        for _ in range(num_steps):\n",
    "            hidden_samples = self.sample_hidden_given_visible(visible_data)\n",
    "            visible_samples = self.sample_visible_given_hidden(hidden_samples)\n",
    "        return visible_samples\n",
    "    \n",
    "    def evaluate(self,y_true, y_hat):\n",
    "        mse = mean_squared_error(y_true, y_hat)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def train(self, data, num_epochs=1,learning_rate=0.1):\n",
    "        f=[]\n",
    "        for i in data:\n",
    "            i=i.reshape(1,14)\n",
    "            m=[]\n",
    "            min_rmse=1000\n",
    "            for j in range(num_epochs):\n",
    "                hidden_samples = self.sample_hidden_given_visible(i)\n",
    "                visible_samples = self.sample_visible_given_hidden(hidden_samples)\n",
    "                \n",
    "                sample_rmse=self.evaluate(i,visible_samples)\n",
    "                \n",
    "                if sample_rmse<min_rmse:\n",
    "                    min_rmse=sample_rmse\n",
    "                    min_sample=hidden_samples\n",
    "                \n",
    "                positive_hidden_activations = np.dot(i, self.weights) + self.hidden_bias\n",
    "                positive_hidden_probs = self.sigmoid(positive_hidden_activations)\n",
    "                positive_associations = np.dot(i.T, positive_hidden_probs)\n",
    "\n",
    "                negative_hidden_activations = np.dot(visible_samples, self.weights) + self.hidden_bias\n",
    "                negative_hidden_probs = self.sigmoid(negative_hidden_activations)\n",
    "                negative_associations = np.dot(visible_samples.T, negative_hidden_probs)\n",
    "\n",
    "                # Update parameters\n",
    "                self.weights += learning_rate * (positive_associations - negative_associations) \n",
    "                self.visible_bias += learning_rate * np.mean(i - visible_samples, axis=0)\n",
    "                self.hidden_bias += learning_rate * np.mean(positive_hidden_probs - negative_hidden_probs, axis=0)\n",
    "                if j==num_epochs-1:\n",
    "                    m.append(min_sample)\n",
    "            f.append(m)\n",
    "        return f\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm=GaussianRBM(14,64)\n",
    "new_x_train=rbm.train(rbm_train,num_epochs=100,learning_rate=0.01)\n",
    "new_x_test=rbm.train(rbm_test,num_epochs=100,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train=np.array(new_x_train).reshape(20631,64)\n",
    "new_x_test=np.array(new_x_test).reshape(13096,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols=[f's_{i}' for i in range(1,65)]\n",
    "nx_train=pd.DataFrame(new_x_train,columns=new_cols)\n",
    "nx_test=pd.DataFrame(new_x_test,columns=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_train[['unit_nr','RUL']]=X_train[['unit_nr','RUL']]\n",
    "nx_test[['unit_nr','RUL']]=X_test[['unit_nr','RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test=[]\n",
    "for i in range(1,101): #change it here\n",
    "    df=nx_test.loc[ex_test['unit_nr']==i]\n",
    "    new_test.append(df.iloc[-25:,0:64].to_numpy())\n",
    "new_test=np.array(new_test).reshape(100,25,64)#change it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences as pad\n",
    "def sequences(x,window=25):\n",
    "    M=[]\n",
    "    N=[]\n",
    "    cnt=[]\n",
    "    for i in range(1,101):\n",
    "        sub_train=x.loc[x['unit_nr']==i]\n",
    "        array=sub_train.to_numpy()\n",
    "        X=[]\n",
    "        Y=[]\n",
    "        count=0\n",
    "        label=list()\n",
    "        for j in range(len(array)-window):\n",
    "            row=[a for a in array[j:j+window,0:64]]\n",
    "            X.append(row)\n",
    "            label=array[j+window,65:66]\n",
    "            Y.append(label)\n",
    "            count+=1\n",
    "        for j in range(len(array)-window,len(array)):\n",
    "            row=[a for a in array[j:len(array),0:64]]\n",
    "            X.append(row)\n",
    "            m=array[len(array)-1,65:66]\n",
    "            Y.append([-100])\n",
    "        cnt.append(count)\n",
    "        padded_sequences = pad(X, padding='post', dtype='float32',value=-100)\n",
    "        M.append(padded_sequences)\n",
    "        N.append(Y)\n",
    "    X_sequences=pad(M, padding='post', dtype='float32',value=-100)\n",
    "    Y_sequences=pad(N, padding='post', dtype='float32',value=-100)\n",
    "    return np.array(X_sequences),np.array(Y_sequences),cnt\n",
    "\n",
    "seq_x_train,seq_y_train,count1=sequences(nx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1,x2,y1,y2=train_test_split(seq_x_train,seq_y_train,test_size=0.2,shuffle=True,random_state=42)\n",
    "func= lambda i: i.reshape(i.shape[0]*i.shape[1],i.shape[2],i.shape[3])\n",
    "x1=func(x1)\n",
    "x2=func(x2)\n",
    "y1=y1.flatten()\n",
    "y2=y2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,441</span> (904.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m231,441\u001b[0m (904.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,441</span> (904.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m231,441\u001b[0m (904.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Masking,Dense,Dropout,LeakyReLU\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import R2Score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Masking(mask_value=-100,input_shape=(25,64)))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(LSTM(128,activation='sigmoid',return_sequences=True))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(LSTM(128,activation='sigmoid'))\n",
    "model1.add(Dense(8,LeakyReLU(0.3)))\n",
    "model1.add(Dense(1, 'linear'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[R2Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 23ms/step - loss: 5729.9424 - root_mean_squared_error: 75.3000 - val_loss: 2174.0024 - val_root_mean_squared_error: 46.6262\n",
      "Epoch 2/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - loss: 1911.9077 - root_mean_squared_error: 43.6938 - val_loss: 2330.6753 - val_root_mean_squared_error: 48.2771\n",
      "Epoch 3/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - loss: 1915.8964 - root_mean_squared_error: 43.6613 - val_loss: 1557.5018 - val_root_mean_squared_error: 39.4652\n",
      "Epoch 4/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - loss: 1478.6515 - root_mean_squared_error: 38.4411 - val_loss: 2436.3689 - val_root_mean_squared_error: 49.3596\n",
      "Epoch 5/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - loss: 2796.8035 - root_mean_squared_error: 52.7991 - val_loss: 2320.0449 - val_root_mean_squared_error: 48.1668\n",
      "Epoch 6/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 1958.9225 - root_mean_squared_error: 44.2250 - val_loss: 1582.9700 - val_root_mean_squared_error: 39.7866\n",
      "Epoch 7/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 1550.7952 - root_mean_squared_error: 39.3706 - val_loss: 1736.7345 - val_root_mean_squared_error: 41.6741\n",
      "Epoch 8/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 1393.4580 - root_mean_squared_error: 37.3193 - val_loss: 1633.3774 - val_root_mean_squared_error: 40.4151\n",
      "Epoch 9/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 1335.3990 - root_mean_squared_error: 36.5379 - val_loss: 1653.7812 - val_root_mean_squared_error: 40.6667\n",
      "Epoch 10/10\n",
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 1273.4316 - root_mean_squared_error: 35.6782 - val_loss: 1620.1653 - val_root_mean_squared_error: 40.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fd508d2cd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x1, y1, validation_data=(x2, y2), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n"
     ]
    }
   ],
   "source": [
    "result=model1.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set RMSE:42.08883462392372\n",
      "-0.025827407836914062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'set RMSE:{rmse}')\n",
    "    r2=r2_score(y_true,y_hat)\n",
    "    print(r2)\n",
    "    \n",
    "evaluate(actual,result.round())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
